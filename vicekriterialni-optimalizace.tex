%!TEX root = main.tex

Zatím jsme se zabývali jen řešením problémů, které obsahují jen jedno kritérium. řešení takových problémů pomocí evoluce je často přímočaré - to jediné kritérium se použije přímo jako fitness, případně se tato fitness může nějakým způsobem škálovat. Nicméně prakticky se často vyskytují problémy, kde je potřeba optimalizovat zároveň kritérií více. Typickým příkladem může třeba být optimalizace tvaru křídla u letadla, od kterého chceme co největší vztlak při co nejmenším čelním odporu. Takové problémy se řeší v oblasti vícekriteriální optimalizace. 

Obecně máme tedy optimalizační problém typu
\begin{equation*}
  \begin{aligned}
  & \underset{x}{\text{min}} 	& & f_1(x), \dots, f_n(x) \\
  & \text{za podmínek} 				& & g_i(x) \leq 0 \\
  & 													& & h_i(x) = 0 \,,\\
  \end{aligned}
\end{equation*}
kde $f_i: D \to \Real$ jsou kritéria a $g_i, h_i: D \to \Real$ jsou omezující podmínky, přičemž $D$ je nějaký prostor parametrů všech těchto funkcí. Například ve spojité optimalizaci to je nějaká podmnožina $\Real^n$, v kombinatorické optimalizaci například množina všech permutací na $\{1, \dots, n\}$.

Prvním z problémů ve vícekriteriální evoluci je, že kritéria si typicky navzájem odporují, tedy dobrá hodnota jednoho kritéria typicky znamená špatnou hodnotu jiného. Řešením problému vícekriteriální evoluce tedy není jeden bod, ale je to celá množina bodů, tzv. Pareto optimální množina. Ta je definována na základě tzv. Pareto dominance. Říkáme, že bod $x$ dominuje bod $y$ ($x \preceq y$) pokud $f_i(x) \leq f_i(y)$ pro všechna $i$ a zároveň $f_j(x) < f_j(y)$ pro alespoň jedno $j$. Pareto optimální množina je potom definovaná jako množina bodů z $D$, které nejsou dominované žádným jiným bodem z $D$. Občas se definuje i tzv. Parto optimální fronta, která se skládá z funkčních hodnot bodů v Pareto optimální množině, tedy pro Pareto optimální množinu $P$ a kritéria $f_1, \dots, f_n$, Pareto optimální fronta je množina $\{(f_1(x), \dots, f_n(x)| x \in P\}$. 

Pareto optimální množina je v typickém případě velká, často dokonce nekonečná (obzvlášť ve spojité optimalizaci), není tedy možné najít jí celou a algoritmy vrací jen nějakou její konečnou aproximaci. Po takové aproximaci typicky chceme, aby body v ní byly blízko skutečně Pareto optimálním bodům (tj. takovým, že je žádný bod nedominuje) a zároveň by měly být víceméně rovnoměrně rozprostřeny po celé Pareto optimální frontě. Těmto dvěma požadavkům se říká konvergence a rozprostření.

\section{Metriky pro porovnání algoritmů}

Problém s porovnáním dvou řešení se opakuje znovu na vyšší úrovni, pokud chceme porovnat dvě různé aproximace Pareto optimální množiny, např. v případě, že chceme sledovat konvergenci algoritmu, nebo chceme porovnat dva různé algoritmy pro vícekriteriální evoluci. Existuje několik různých metrik, které nějakým způsobem porovnávají dvě aproximace Pareto optimální množiny (vetšinou pracují s Pareto optimální frontou). 

Jednou z prvních bylo tzv. pokrytí (cover), které je pro dvě stejně velké aproximace Pareto fronty $A, B$ definované jako 
$$\mathcal{C}(A, B) = \frac{\text{počet bodů z množiny $B$ dominovaných body z množiny $A$}}{\text{počet bodů v množině $A$}}\,.$$
Nevýhodou tohoto kritéria je, že je binární, tj. pokud chceme porovnávat více aproximací, musíme porovnání udělat pro každou dvojici. Navíc kritérium vyjadřuje hlavně konvergenci k Pareto optimální frontě.

Častěji se používají tzv. unární indikátory, které vyjadřují kvalitu nalezené aproximace jako jedno číslo. Příkladem může být například tzv. generační vzdálenost (generational distance, GD), která je pro aproximaci $A$ Pareto optimální fronty $P$ definována jako průměrná vzdálenost bodu z $A$ k bodu z $P$. Lepší aproximace mají menší hodnoty GD. Zásadní problém GD je, že vyjadřuje jen konvergenci, pokud budou všechny body z $A$ těsně u sebe a blízko k Pareto optimální frontě, hodnota GD bude nízká. Tento problém řeší inverzní GD (IGD), která místo toho počítá vzdálenost od každého bodu z $P$ k nejbližšímu bodu z $A$. Tímto postupem se započítá jako konvergence tak rozprostření.

V současnosti se nejčastěji jako indikátor kvality nalezeného řešení používá hyperobjem prostoru dominovaného danou aproximací Pareto optimální fronty. Formálně se dá pro aproximaci Pareto optimální fronty $A$ a referenční bod $r\in \mathbb{R^n}$ jako 
$$
\mathrm{H}(A,r)=\int_{\Real^n}\mathrm{Char}(\{x\in \Real^n\,\exists a\in A\, a\preceq x\preceq r\})(z)\, dz\,,
$$
kde $\mathrm{Char}(X)$ je charakteristická funkce množiny $X$. Jako referenční bod $r$ se často volí vektor $(1, \dots, 1)$ po té, co se celá aproximace naškáluje na interval $[0,1]$. Výhodou hyperbojemu je, že (podobně jako IGD) kombinuje jak konvergenci tak rozprostření. Jeho nevýhodou naopak je, že jeho výpočet roste s počtem kritérií a problém jeho výpočtu je ve skutečnosti $\#\mathrm{P}$-úplný.

\bigskip

Evoluční algoritmy pro vícekriteriální evoluci se od jiných evolučních algoritmů liší především ve způsobu, jakým provádějí selekci. Použité genetické operátory jsou závislé na typu řešeného problému a kódování jedince a nijak se neliší od postupů používaných v jednokriteriální evoluci. 

Jedním z prvních evolučních algoritmů, který se snažil řešit problém vícekriteriální evoluce byl algoritmus VEGA (Vector Evaluated Genetic Algorithm) navržený už v 80. letech. V tomto algoritmu se různé části populace vybíraly pomocí různých kritérií. Takový algoritmus ale z dnešního pohledu moc dobře nefunguje, neboť často konverguje k optimům jednotlivých kritérií a kompromisní řešení se moc často neobjevují. Moderní vícekriteriální algoritmy pak jde rozdělit do dvou skupin -- na algoritmy založené přímo na Pareto dominanci (např. NSGA-II a MO-CMA-ES popsané níže) a na algoritmy založené na dekompozici vícekriteriálního problému na množinu jednokriteriálních (např. MOEA/D popsaný na konci této kapitoly).


\section{Evoluční algoritmus s nedominovaným tříděním}

Přímo na základě Pareto dominování lze definovat fitness funkci v evolučním algoritmu. Takový postup používá mnoho vícekriteriálních algoritmů, jako příklad si ukážeme populární algoritmus NSGA-II (Non-dominated Sorting Genetic ALgorithm II). Myšlenkou nedominovaného třídění je, že pokud vezmeme dva jedince z populace a jeden z nich dominuje druhého, je určitě lepší. Při selekci se tedy jedinci rozdělí do tzv. nedominovaných front -- v první frontě jsou jedinci, kteří nejsou dominováni žádnými jinými jedinci v populaci, v druhé frontě jsou jedinci, kteří jsou dominováni jen jedinci z první fronty atd.
Tímto způsobem se celé populace rozdělí do několika front přičemž jedinci ve frontě s menším číslem se považují za lepší, než jedinci ve frontě s vyšším číslem. Pro porovnání jedinců ve stejné frontě potřebuje nějaké druhotné kritérium. Zde původní verze NSGA-II uvažuje crowding distance, v zásadě jde o vzdálenost jedince od nejbližších jedinců ve stejné Pareto optimální frontě. Jedinci s vyšší hodnotou této vzdálenosti jsou lepší, než jedinci s menší hodnotou, protože jsou v částech prostoru, které jsou méně obsazeny. 

Výše popsaná selekce sama o sobě nezajišťuje žádnou formu elitismu. Ten se do algoritmu dostane tak, že se před environmentální selekcí populace rodičů a potomků sloučí do jedné, ze které se potom výše popsaným způsobem vybere správný počet nejlepších jedinců. Selekce je tedy deterministická.

Algoritmus NSGA-II funguje relativně dobře pro problémy s dvěma nebo třemi kritérii, ale právě kvůli nedominovanému třídění má problém, pokud je počet kritérií větší. V takovém případě je totiž mnohem větší šance, že dva jedinci budou navzájem nedominovaní. To potom vede k tomu, že většina jedinců v populaci patří do první nedominované fronty a algoritmus ztrácí jakýkoliv tlak na konvergenci k Pareto optimální frontě (optimalizují se jen vzdálenosti mezi řešeními). Tento problém se dá částečně obejít tím, že se druhotné třídící kritérium nahradí za nějaké jiné, např. za příspěvek daného jedince k hyperobjemu celé nedominované fronty. Ačkoliv to situaci trochu zlepšuje, NSGA-II typicky nefunguje moc dobře pro problémy s více než třemi kritérii.

\section{Vícekriteriální evoluční strategie}

V případě, že chceme řešit vícekriteriální problémy ve spojité optimalizaci, může se nám hodit vícekriteriální verze evoluční strategie CMA-ES, tedy algoritmus MO-CMA-ES. Ten je zajímavý i tím, že každý jedinec v jeho populaci je vlastně instance $(1+1)-CMA-ES$, v populaci $\mu$ jedinců tak máme vlastně $\mu$ nezávislých instancí CMA-ES algoritmu. 

V každé generaci MO-CMA-ES každý jedinec vygeneruje nové řešení pomocí své instance $(1+1)$-CMA-ES. Toto řešení se porovná s rodičem a pokud je lepší (tj. dominuje ho, nebo jsou obě řešení neporovnatelná a potomek je lepší v druhotném kritérium) aktualizují se parametry jeho instance CMA-ES. Na konci generace se použije selekce z NSGA-II algoritmu, která rozhodne, kteří jedinci přežijí do další generace. 

Nevýhodou toho, že algoritmus obsahuje nezávislé instance CMA-ES je to, že se endogenní parametry těchto strategií adaptují velmi pomalu. Byla proto navžena i verze se sdílenými parametry, která tento problém řeší. I MO-CMA-ES, kvůli tomu, že používá stejnou selekci jako NSGA-II, má problém s větším množstvím kritérií. 

\section{Vícekriteriální evoluce založená na dekompozici}

Problém vícekriteriální optimalizace se dá řešit pomocí jeho transformace na jednokriteriální optimalizaci. Většinou se tím vícekriteriální problém převede na několik jednokriteriálních problémů (proto se tomuto přístupu také říká \uv{dekompozice}). Takový postup je relativně jednoduchý a umožňuje přímo použít existující evoluční algoritmy, ale na druhou stranu při naivní implementaci potřebuje pro nalezení každého řešení spustit nový běh algoritmu. 

Jednou z možností jak takovou transformaci udělat je použít vážený součet kritérií jako fitness funkci, tj. $$f(x) = \sum_{i=1}^n w_if_i(x)\,,$$ kde $w_i$ jsou váhy mezi 0 a 1. Tento způsob ale má zásadní nevýhodu -- funguje jen v případě, že Pareto optimální fronta je konvexní. Z tohoto pohledu je lepší tzv. Čebyševova dekompozice, která funkci definuje jako $$f(x) = \lambda_i|f_i(x) - f^*_i|\,,$$ kde $\lambda_i$ jsou opět váhy mezi 0 a 1 a $f^*_i = \min_x f_i(x)$. Takový způsob dekompozice funguje i pro nekonvexní Pareto optimální fronty.

Již jsme zmínili, že tyto dekompozice se typicky nepoužívají přímo, algoritmus MOEA/D (Multiobjective Evolutionary Algorithm Based on Decomposition) je ale právě na těchto dekompozicích založený. Místo toho, aby řešil postupně několik jednokriteriálních problémů, řeší je všechny najednou a využívá navíc předpokladu, že podobné problémy (s podobnými vahami $w_i$, nebo $\lambda_i$) budou nejspíš mít podobná řešení. V MOEA/D odpovídá každý jedinec jednomu nastavení vah a předpokladu se využívá tak, že se definují okolí jedinců jako množiny řešení, které mají nejpodobnější váhy. Genetické operátory se potom s velkou pravděpodobností (typicky kolem 90 \%) pouští jen na jedincích, kteří jsou v okolí. V rámci mutace je navíc možnost jedince vylepšit problémově-specifickou heuristikou. Po aplikaci genetických operátorů se jedinec porovná se svým rodičem, a pokud je lepší, nahradí ho. Zároveň se porovná i s ostatními jedinci v okolí a také je nahradí, pokud je lepší pro dekompozici, která jim odpovídá. V zájmu zachování diverzity v populaci se většinou počet jedinců nahrazených v okolí omezuje -- typická hodnota jsou maximálně dva nahrazení jedinci.

Díky svému způsobu selekce a dekompozici problému na jednokriteriální problémy funguje algoritmus MOEA/D dobře i pro problémy s větším množstvím kritérií.