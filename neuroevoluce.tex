Použití evolučních algoritmů pro učení neuronových sítí je oblast zkoumaná od přelomu osmdesátých a devadesátých let. První pokusy se týkaly učení vah sítě s předem danou strukturou, jde tedy o využití evolučního algoritmu jako alternativy ke standardnímu učení neuronových sítí založených typicky na lokálních metodách gradientní optimalizace \cite{neuro}. 
Tato úloha není příliš složitá, parametry sítě zakódujeme do reálného vektoru a na něj použijeme jeden z výše popsaných algoritmů. Výpočet fitness pak znamená spočítat chybu neuronové sítě na množině trénovacích dat.

Dnes z experimentů víme, že evoluční algoritmus těžko soupeří v rychlosti s nejlepšími gradientními algoritmy, nicméně jeho výhody pro učení parametrů sítě jsou robustnost proti uváznutí v lokálních extrémech a snadná paralelizace. Jednou z oblastí, kde je evoluční algoritmus pro učení neuronových síti nezastupitelný, jsou případy tzv. posilováného učení, kde není k dispozici informace o chybě sítě pro každý vstup. Tyto případy jsou velmi časté v robotice, kdy teprve z chování robota v delším časovém úseku můžeme odvodit jeho úspěšnost. V této oblasti je evoluční učení neuronových sítí takřka nezastupitelné, i proto se často hovoří o oboru evoluční robotiky. 

Schopnost evoluční algoritmů optimalizovat i složitěji reprezentované struktury vedla ke snahám použít je pro optimalizaci velikosti a propojení jednotek uvnitř sítě, mluvíme o strukturálním učení. Toto učení lze rozdělit podle toho, zda reprezentace sítě je zakódovaná do jedince evolučního algoritmu přímo či nepřímo. Další dělení je, zda se struktura učí najednou společně s parametry sítě (takže kódujeme obě komponenty v jednom genomu) anebo se struktura učí zvlášť a učení parametrů sítě je vlastně záležitostí výpočtu fitness jedince. Při tomto rozdělení úlohy na učení struktury a parametrů je zajímavé si uvědomit, že učit parametry lze libovolným algoritmem, třeba další evolucí.

Při přímých metodách učení struktury sítě se většinou pracuje s reprezentací pomocí matice propojení neuronů v síti. Tato matice může být booleovská (v připadě reprezentace struktury) nebo reálná (pro reprezentaci struktrury i hodnot vah spojů v síti). Jelikož matice propojení může být poměrně velká, vznikly snahy o kompaktní vyjádření struktury sítě, které je často nepřímé. Kitano navrhl gramatické kódování booleovské matice spojů, které uvažuje dvojrozměrnou gramatiku schopnou v logaritmickém prostoru popsat matice navíc s možnosti zachytit symetrie struktury. Gruau navrhl jinou metodu založenou na principu genetického programování, kde program je vlastně návod na sestrojení sítě metodou růstu z minimální konfigurace \cite{gruau}. 

Jednou z dnes nejúspěšnějších neuroevolučních metod je Stanleyho Neat (neuroevolution of augmenting topologies) \cite{stanley}. Jde o přímou metodu vyvíjející zároveň strukturu i parametry sítě opět postupem od minimální konfigurace ke složitějším. Autor elegantně vyřešil problém, jak má vlastně vypadat křížení dvou sítí s různou topologií. Používá k tomu globální paměť evoluční historie tvaru sítě jednoduše realizovatelnou pomocí tzv. rodného čísla spoje, díky kterému lze určit, které hrany v grafu sítě si evolučně odpovídají, a ty se pak mohou křížit. Důležitým problémem při současném učení struktury a parametrů se ukázal krátkodobý negativní vliv strukturálních změn na kvalitu sítě a z toho vyplývající nutnost ochrany strukturálně nových jedinců, kteří potřebují čas na doladění svých parametrů. To je v Neatu opět řešeno pomocí využití rodných čísel hran pro určení podobných sítí a relativizací fitness uvnitř množin podobných sítí. 

