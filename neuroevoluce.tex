Pou¾ití evoluèních algoritmù pro uèení neuronových sítí je oblast zkoumaná od pøelomu osmdesátých a devadesátých let. První pokusy se týkaly uèení vah sítì s pøedem danou strukturou, jde tedy o vyu¾ití evoluèního algoritmu jako alternativy ke standardnímu uèení neuronových sítí zalo¾ených typicky na lokálních metodách gradientní optimalizace \cite{neuro}. 
Tato úloha není pøíli¹ slo¾itá, parametry sítì zakódujeme do reálného vektoru a na nìj pou¾ijeme jeden z vý¹e popsaných algoritmù. Výpoèet fitness pak znamená spoèítat chybu neuronové sítì na mno¾inì trénovacích dat.

Dnes z experimentù víme, ¾e evoluèní algoritmus tì¾ko soupeøí v rychlosti s nejlep¹ími gradientními algoritmy, nicménì jeho výhody pro uèení parametrù sítì jsou robustnost proti uváznutí v lokálních extrémech a snadná paralelizace. Jednou z oblastí, kde je evoluèní algoritmus pro uèení neuronových síti nezastupitelný, jsou pøípady tzv. posilováného uèení, kde není k dispozici informace o chybì sítì pro ka¾dý vstup. Tyto pøípady jsou velmi èasté v robotice, kdy teprve z chování robota v del¹ím èasovém úseku mù¾eme odvodit jeho úspì¹nost. V této oblasti je evoluèní uèení neuronových sítí takøka nezastupitelné, i proto se èasto hovoøí o oboru evoluèní robotiky. 

Schopnost evoluèní algoritmù optimalizovat i slo¾itìji reprezentované struktury vedla ke snahám pou¾ít je pro optimalizaci velikosti a propojení jednotek uvnitø sítì, mluvíme o strukturálním uèení. Toto uèení lze rozdìlit podle toho, zda reprezentace sítì je zakódovaná do jedince evoluèního algoritmu pøímo èi nepøímo. Dal¹í dìlení je, zda se struktura uèí najednou spoleènì s parametry sítì (tak¾e kódujeme obì komponenty v jednom genomu) anebo se struktura uèí zvlá¹» a uèení parametrù sítì je vlastnì zále¾itostí výpoètu fitness jedince. Pøi tomto rozdìlení úlohy na uèení struktury a parametrù je zajímavé si uvìdomit, ¾e uèit parametry lze libovolným algoritmem, tøeba dal¹í evolucí.

Pøi pøímých metodách uèení struktury sítì se vìt¹inou pracuje s reprezentací pomocí matice propojení neuronù v síti. Tato matice mù¾e být booleovská (v pøipadì reprezentace struktury) nebo reálná (pro reprezentaci struktrury i hodnot vah spojù v síti). Jeliko¾ matice propojení mù¾e být pomìrnì velká, vznikly snahy o kompaktní vyjádøení struktury sítì, které je èasto nepøímé. Kitano navrhl gramatické kódování booleovské matice spojù, které uva¾uje dvojrozmìrnou gramatiku schopnou v logaritmickém prostoru popsat matice navíc s mo¾nosti zachytit symetrie struktury. Gruau navrhl jinou metodu zalo¾enou na principu genetického programování, kde program je vlastnì návod na sestrojení sítì metodou rùstu z minimální konfigurace \cite{gruau}. 

Jednou z dnes nejúspì¹nìj¹ích neuroevoluèních metod je Stanleyho Neat (neuroevolution of augmenting topologies) \cite{stanley}. Jde o pøímou metodu vyvíjející zároveò strukturu i parametry sítì opìt postupem od minimální konfigurace ke slo¾itìj¹ím. Autor elegantnì vyøe¹il problém, jak má vlastnì vypadat køí¾ení dvou sítí s rùznou topologií. Pou¾ívá k tomu globální pamì» evoluèní historie tvaru sítì jednodu¹e realizovatelnou pomocí tzv. rodného èísla spoje, díky kterému lze urèit, které hrany v grafu sítì si evoluènì odpovídají, a ty se pak mohou køí¾it. Dùle¾itým problémem pøi souèasném uèení struktury a parametrù se ukázal krátkodobý negativní vliv strukturálních zmìn na kvalitu sítì a z toho vyplývající nutnost ochrany strukturálnì nových jedincù, kteøí potøebují èas na doladìní svých parametrù. To je v Neatu opìt øe¹eno pomocí vyu¾ití rodných èísel hran pro urèení podobných sítí a relativizací fitness uvnitø mno¾in podobných sítí. 

