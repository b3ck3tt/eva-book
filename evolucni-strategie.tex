%!TEX root = main.tex

\emph{Evoluèní strategie}\cite{rechenberg1973,schwefel1977numerische} jsou z historického hlediska jistou alternativou Hollandova genetického algoritmu. Jsou o nìco star¹í a je na nich zajímavé, ¾e jsou o nìco komplikovanìj¹í. V souèasnosti se pou¾ívají pøedev¹ím pro øe¹ení problémù spojité optimalizace, ale my¹lenky, které se v této oblasti vyskytují, se dají pou¾ít i jinde.

Evoluèní strategie se dìlí do dvou skupin podle zpùsobu, jakým pracují s populacemi rodièù a potomkù. V obou pøípadech jsou dùle¾ité parametry $\mu$ a $\lambda$, které oznaèují poèet rodièù a poèet potomkù, kteøí z nich vznikají. Pro druhy evoluèních strategií potom existuje ustálené znaèení $(\mu, \lambda)$-ES a $(\mu + \lambda)$-ES. V prvním pøípadì (``èárková selekce'') máme populaci $\mu$ rodièù, ze kterých vytvoøíme $\lambda$ potomkù ($\lambda > \mu$), z tìch potom vybereme nejlep¹ích $\mu$ jako rodièe do dal¹í generace.  Ve druhém pøípadì (``plus selekce'') z $\mu$ rodièù vytvoøíme opìt $\lambda$ potomkù, ale pøed selekcí napøed slouèíme rodièe a potomky do jedné populace velikosti $\mu + \lambda$. Z té se potom opìt vybere $\mu$ nejlep¹ích jedincù jako rodièe do dal¹í generace. 

Jednou ze základních vlastností evoluèních strategií, které je odli¹ují od jiných typù evoluèních algoritmù je to, ¾e obsahují nìjakou formu samo-adaptace parametrù. V pøípadì spojité optimalizace se tedy kromì samotných hodnot vektoru vyvíjí napøíklad i parametry pro mutaci. Technicky se tedy potom jedinec skládá ze dvou èástí -- samotného zakódovaného vektoru èísel $\vec{x}$ a vektoru tzv. \emph{endogenních parametrù} $\vec{s}$, které právì obsahují v¹echny parametry, které ovlivòují chování operátorù\footnote{Vedle pojmu ``endogenní parametry'' se je¹tì obèas objevuje pojem ``exogenní parametry'', který oznaèuje parametry algoritmu, které se nemìní, jako napø. velikost populace.}. Je dùle¾ité si uvìdomit, ¾e endogenní parametry nijak pøímo neovlivòují fitness jedince, jejich hodnoty se vyvíjí jen díky tomu, ¾e jedinci s lep¹í hodnotou endogenních parametrù mají po aplikaci genetických operátorù èastìji lep¹í fitness. Pro samotnou evoluci endogenních parametrù se mohou pou¾ívat stejné operátory jako pro samotného jedince s fixnì nastavenými parametry, nicménì moderní evoluèní strategie èastìji pou¾ívají deterministický zpùsob nastavení tìchto parametrù.

Dùle¾itou souèástí evoluèních strategií je rekombinace. Ta v zásadì odpovídá køí¾ení v genetických algoritmech a jejím cílem je vytvoøit nového jedince kombinací jedincù z populace. V evoluèních strategiích se ale velmi èasto pou¾ívají rekombinace, které kombinují v¹echny jedince. Èastá je tzv. \emph{interpolaèní rekombinace}, která jednodu¹e spoèítá prùmìr v¹ech jedincù v populaci -- nový jedinec je vlastnì centroid celé populace. Pou¾ívá se i její varianta, která pou¾ívá vá¾ený souèet, kde lep¹í jedinci v populaci mají vìt¹í váhu pøi výpoètu prùmìru (nejhor¹í jedinci se dokonce mohou úplnì ignorovat). Kromì tìchto dvou nejèastìji pou¾ívaných rekombinací se dají pou¾ívat i køí¾ení známá z genetických algoritmù, není to ale moc obvyklé. Existuje i uniformní rekombinace, která ka¾dou slo¾ku vektoru jedince vybírá z náhodného jedince v populace. 

Pou¾itá rekombinace se obèas objevuje i v notaci evoluèních strategií, v takovém pøípadì se pí¹e jako $(\lambda/\rho + \mu)$, kde právì $\rho$ oznaèuje pou¾itou rekombinaci.

Základním operátorem v evoluèních strategiích ale je mutace. Typicky jde o gaussovskou mutaci s urèitým rozptylem. Zde se objevuje nìkolik mo¾ností, kde nejjednodu¹¹í je sférická mutace, která pøièítá k jedinci vektor z normálního rozdìlení $\sigma\normal{0}{I}$, kde $I$ je jednotková matice. O nìco slo¾itìj¹í varianta potom pou¾ívá jiný rozptyl pro ka¾dou souøadnici vektoru, tj. k jedinci se pøièítá hodnota z normálního rozdìlení $\normal{0}{\mathrm{diag}({\vec{\sigma}})}$, kde $\mathrm{diag}(\sigma)$ znaèí diagonální matici s vektorem $\vec{\sigma}$ na hlavní diagonále. Koneènì v nejkomplikovanìj¹ím pøípadì se jedinci generují s normálního rozdìlení s plnou kovarianèní matici $\normal{0}{\Sigma}$. Aèkoliv první dva zpùsoby vy¾adují mnohem ni¾¹í mno¾ství endogenních parametrù (1 respektive $d$), jejich nevýhoda spoèívá v tom, ¾e nejsou schopny zachytit závislosti mezi parametry a hodí se tak pøedev¹ím pro separabilní problémy. Na druhou stranu zpùsob s plnou kovarianèní maticí je invariantní vùèi rotacím a ¹kálovaní prohledávaného prostoru (a díky dal¹ím vlastnostem evoluèních strategií i k monotónnímu ¹kálování fitness funkce).

\newcommand{\fifth}{\sfrac{1}{5}\xspace}

\section{Pravidlo jedné pìtiny}

Vzhledem k relativnì velkému mno¾ství endogenních parametrù v evoluèních strategiích a k tomu, ¾e vhodné nastavení parametrù je rùzné pro rùzné optimalizaèní problémy a dokonce i v rùzných fázích evoluce, vznikla potøeba parametry nastavovat adaptivnì. Pøi pevném nastavení velikosti mutace typicky pozorujeme tøi fáze evoluce. V první fázi evoluce je konvergence pomalá, proto¾e zmìny dìlané mutací jsou pøíli¹ malé. Následuje fáze rychlé konvergence, kde jsou velikosti zmìn optimální pro danou fázi výpoètu, a v poslední fázi se konvergence zase zpomalí, proto¾e jsou zmìny moc velké (algoritmus ``skáèe'' kolem optima).

První metoda adaptivního nastavování vze¹la z Rechenbergových experimentù,\cite{rechenberg1973} které zkoumaly vliv rozptylu Gaussovské mutace v $(1+1)$-ES pøi optimalizaci dvou funkcí. Ukázalo se, ¾e pro obì funkce algoritmus nejrychleji konverguje, pokud se velikost mutace zmen¹í, kdy¾ je pravdìpodobnost, ¾e je potomek lep¹í ne¾ rodiè men¹í ne¾ cca \fifth, a zvìt¹í, kdy¾ je tato pravdìpodobnost vìt¹í ne¾ cca \fifth. Z tohoto pozorování vzniklo pravidlo \fifth.\sidenote{V angliètinì ``one fifth rule''}

Proè takové pravidlo funguje? Pøedstavme si optimalizaci lineární funkce, v takovém pøípadì je pravdìpodobnost, ¾e potomek je lep¹í ne¾ rodiè, pøesnì 50\%. 
Obecnou funkci mù¾eme v ka¾dém bodì podle Taylorova pravidla aproximovat pomocí lineární funkce, tato aproximace je tím pøesnìj¹í, èím blí¾e jsme bodu, ve kterém jsme funkci aproximovali, tedy, pøi malé velikosti mutace bude vìt¹ina potomkù blízko a pravdìpodobnost, ¾e jsou lep¹í ne¾ rodiè, je kolem 50\%. Naopak, pøi nekoneèném rozptylu mutace pravdìpodobnost zlep¹ení odpovídá èásti prostoru, kde má funkce lep¹í hodnotu, ne¾ v daném bodì. Ve chvíli, kdy se algoritmu pøiblí¾í optimu je tato pravdìpodobnost vìt¹inou blízko 0. Ve skuteènosti se dokonce ukazuje, ¾e pro vìt¹inu funkcí pravdìpodobnost zlep¹ení monotónnì roste s klesajícím rozptylem mutace. Pøesná hodnota pro optimální pravdìpodobnost zlep¹ení závisí na optimalizované funkci, nicménì právì \fifth je èasto doporuèovaná.

