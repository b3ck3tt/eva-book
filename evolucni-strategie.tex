%!TEX root = main.tex

\emph{Evoluční strategie}\cite{rechenberg1973,schwefel1977numerische} jsou z historického hlediska jistou alternativou Hollandova genetického algoritmu. Jsou o něco starší a je na nich zajímavé, že jsou o něco komplikovanější. V současnosti se používají především pro řešení problémů spojité optimalizace, ale myšlenky, které se v této oblasti vyskytují, se dají použít i jinde.

Evoluční strategie se dělí do dvou skupin podle způsobu, jakým pracují s populacemi rodičů a potomků. V obou případech jsou důležité parametry $\mu$ a $\lambda$, které označují počet rodičů a počet potomků, kteří z nich vznikají. Pro druhy evolučních strategií potom existuje ustálené značení $(\mu, \lambda)$-ES a $(\mu + \lambda)$-ES. V prvním případě (``čárková selekce'') máme populaci $\mu$ rodičů, ze kterých vytvoříme $\lambda$ potomků ($\lambda > \mu$), z těch potom vybereme nejlepších $\mu$ jako rodiče do další generace.  Ve druhém případě (``plus selekce'') z $\mu$ rodičů vytvoříme opět $\lambda$ potomků, ale před selekcí napřed sloučíme rodiče a potomky do jedné populace velikosti $\mu + \lambda$. Z té se potom opět vybere $\mu$ nejlepších jedinců jako rodiče do další generace. 

Jednou ze základních vlastností evolučních strategií, které je odlišují od jiných typů evolučních algoritmů je to, že obsahují nějakou formu samo-adaptace parametrů. V případě spojité optimalizace se tedy kromě samotných hodnot vektoru vyvíjí například i parametry pro mutaci. Technicky se tedy potom jedinec skládá ze dvou částí -- samotného zakódovaného vektoru čísel $\vec{x}$ a vektoru tzv. \emph{endogenních parametrů} $\vec{s}$, které právě obsahují všechny parametry, které ovlivňují chování operátorů\footnote{Vedle pojmu ``endogenní parametry'' se ještě občas objevuje pojem ``exogenní parametry'', který označuje parametry algoritmu, které se nemění, jako např. velikost populace.}. Je důležité si uvědomit, že endogenní parametry nijak přímo neovlivňují fitness jedince, jejich hodnoty se vyvíjí jen díky tomu, že jedinci s lepší hodnotou endogenních parametrů mají po aplikaci genetických operátorů častěji lepší fitness. Pro samotnou evoluci endogenních parametrů se mohou používat stejné operátory jako pro samotného jedince s fixně nastavenými parametry, nicméně moderní evoluční strategie častěji používají deterministický způsob nastavení těchto parametrů.

Důležitou součástí evolučních strategií je rekombinace. Ta v zásadě odpovídá křížení v genetických algoritmech a jejím cílem je vytvořit nového jedince kombinací jedinců z populace. V evolučních strategiích se ale velmi často používají rekombinace, které kombinují všechny jedince. Častá je tzv. \emph{interpolační rekombinace}, která jednoduše spočítá průměr všech jedinců v populaci -- nový jedinec je vlastně centroid celé populace. Používá se i její varianta, která používá vážený součet, kde lepší jedinci v populaci mají větší váhu při výpočtu průměru (nejhorší jedinci se dokonce mohou úplně ignorovat). Kromě těchto dvou nejčastěji používaných rekombinací se dají používat i křížení známá z genetických algoritmů, není to ale moc obvyklé. Existuje i uniformní rekombinace, která každou složku vektoru jedince vybírá z náhodného jedince v populace. 

Použitá rekombinace se občas objevuje i v notaci evolučních strategií, v takovém případě se píše jako $(\lambda/\rho + \mu)$, kde právě $\rho$ označuje použitou rekombinaci.

Základním operátorem v evolučních strategiích ale je mutace. Typicky jde o gaussovskou mutaci s určitým rozptylem. Zde se objevuje několik možností, kde nejjednodušší je sférická mutace, která přičítá k jedinci vektor z normálního rozdělení $\sigma\normal{0}{I}$, kde $I$ je jednotková matice. O něco složitější varianta potom používá jiný rozptyl pro každou souřadnici vektoru, tj. k jedinci se přičítá hodnota z normálního rozdělení $\normal{0}{\mathrm{diag}({\vec{\sigma}})}$, kde $\mathrm{diag}(\sigma)$ značí diagonální matici s vektorem $\vec{\sigma}$ na hlavní diagonále. Konečně v nejkomplikovanějším případě se jedinci generují s normálního rozdělení s plnou kovarianční matici $\normal{0}{\Sigma}$. Ačkoliv první dva způsoby vyžadují mnohem nižší množství endogenních parametrů (1 respektive $d$), jejich nevýhoda spočívá v tom, že nejsou schopny zachytit závislosti mezi parametry a hodí se tak především pro separabilní problémy. Na druhou stranu způsob s plnou kovarianční maticí je invariantní vůči rotacím a škálovaní prohledávaného prostoru (a díky dalším vlastnostem evolučních strategií i k monotónnímu škálování fitness funkce).

Vzhledem k relativně velkému množství endogenních parametrů v evolučních strategiích a k tomu, že vhodné nastavení parametrů je různé pro různé optimalizační problémy a dokonce i v různých fázích evoluce, vznikla potřeba parametry nastavovat adaptivně. Při pevném nastavení velikosti mutace typicky pozorujeme tři fáze evoluce. V první fázi evoluce je konvergence pomalá, protože změny dělané mutací jsou příliš malé. Následuje fáze rychlé konvergence, kde jsou velikosti změn optimální pro danou fázi výpočtu, a v poslední fázi se konvergence zase zpomalí, protože jsou změny moc velké (algoritmus ``skáče'' kolem optima).

\newcommand{\fifth}{\sfrac{1}{5}\xspace}

\section{Pravidlo jedné pětiny}

První metoda adaptivního nastavování vzešla z Rechenbergových experimentů,\cite{rechenberg1973} které zkoumaly vliv rozptylu Gaussovské mutace v $(1+1)$-ES při optimalizaci dvou funkcí. Ukázalo se, že pro obě funkce algoritmus nejrychleji konverguje, pokud se velikost mutace zmenší, když je pravděpodobnost, že je potomek lepší než rodič menší než cca \fifth, a zvětší, když je tato pravděpodobnost větší než cca \fifth. Z tohoto pozorování vzniklo pravidlo \fifth.\sidenote{V angličtině ``one fifth rule''}

Proč takové pravidlo funguje? Představme si optimalizaci lineární funkce, v takovém případě je pravděpodobnost, že potomek je lepší než rodič, přesně 50\%. 
Obecnou funkci můžeme v každém bodě podle Taylorova pravidla aproximovat pomocí lineární funkce, tato aproximace je tím přesnější, čím blíže jsme bodu, ve kterém jsme funkci aproximovali, tedy, při malé velikosti mutace bude většina potomků blízko a pravděpodobnost, že jsou lepší než rodič, je kolem 50\%. Naopak, při nekonečném rozptylu mutace pravděpodobnost zlepšení odpovídá části prostoru, kde má funkce lepší hodnotu, než v daném bodě. Ve chvíli, kdy se algoritmu přiblíží optimu je tato pravděpodobnost většinou blízko 0. Ve skutečnosti se dokonce ukazuje, že pro většinu funkcí pravděpodobnost zlepšení monotónně roste s klesajícím rozptylem mutace. Přesná hodnota pro optimální pravděpodobnost zlepšení závisí na optimalizované funkci, nicméně právě \fifth je často doporučovaná.

\section{Sebe-adaptivní evoluční strategie}

Jiný přístup k sebe-adaptaci endogenních parametrů zvolil Schweffel\cite{schwefel1977numerische}, ten pro jejich ladění použil podobné genetické operátory, jako se používají pro samotné zakódované řešení. Konkrétně se každý endogenní parametr vynásobil číslem $e^{\normal{0}{I}}$.