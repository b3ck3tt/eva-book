%!TEX root = main.tex

\emph{Evoluční strategie}\cite{rechenberg1973,schwefel1977numerische} jsou z historického hlediska jistou alternativou Hollandova genetického algoritmu. Jsou o něco starší a je na nich zajímavé, že jsou o něco komplikovanější. V současnosti se používají především pro řešení problémů spojité optimalizace, ale myšlenky, které se v této oblasti vyskytují, se dají použít i jinde.

Evoluční strategie se dělí do dvou skupin podle způsobu, jakým pracují s populacemi rodičů a potomků. V obou případech jsou důležité parametry $\mu$ a $\lambda$, které označují počet rodičů a počet potomků, kteří z nich vznikají. Pro druhy evolučních strategií potom existuje ustálené značení $(\mu, \lambda)$-ES a $(\mu + \lambda)$-ES. V prvním případě (``čárková selekce'') máme populaci $\mu$ rodičů, ze kterých vytvoříme $\lambda$ potomků ($\lambda > \mu$), z těch potom vybereme nejlepších $\mu$ jako rodiče do další generace.  Ve druhém případě (``plus selekce'') z $\mu$ rodičů vytvoříme opět $\lambda$ potomků, ale před selekcí napřed sloučíme rodiče a potomky do jedné populace velikosti $\mu + \lambda$. Z té se potom opět vybere $\mu$ nejlepších jedinců jako rodiče do další generace. 

Jednou ze základních vlastností evolučních strategií, které je odlišují od jiných typů evolučních algoritmů je to, že obsahují nějakou formu samo-adaptace parametrů. V případě spojité optimalizace se tedy kromě samotných hodnot vektoru vyvíjí například i parametry pro mutaci. Technicky se tedy potom jedinec skládá ze dvou částí -- samotného zakódovaného vektoru čísel $\vec{x}$ a vektoru tzv. \emph{endogenních parametrů} $\vec{s}$, které právě obsahují všechny parametry, které ovlivňují chování operátorů\footnote{Vedle pojmu ``endogenní parametry'' se ještě občas objevuje pojem ``exogenní parametry'', který označuje parametry algoritmu, které se nemění, jako např. velikost populace.}. Je důležité si uvědomit, že endogenní parametry nijak přímo neovlivňují fitness jedince, jejich hodnoty se vyvíjí jen díky tomu, že jedinci s lepší hodnotou endogenních parametrů mají po aplikaci genetických operátorů častěji lepší fitness. Pro samotnou evoluci endogenních parametrů se mohou používat stejné operátory jako pro samotného jedince s fixně nastavenými parametry, nicméně moderní evoluční strategie častěji používají deterministický způsob nastavení těchto parametrů.

Důležitou součástí evolučních strategií je rekombinace. Ta v zásadě odpovídá křížení v genetických algoritmech a jejím cílem je vytvořit nového jedince kombinací jedinců z populace. V evolučních strategiích se ale velmi často používají rekombinace, které kombinují všechny jedince. Častá je tzv. \emph{interpolační rekombinace}, která jednoduše spočítá průměr všech jedinců v populaci -- nový jedinec je vlastně centroid celé populace. Používá se i její varianta, která používá vážený součet, kde lepší jedinci v populaci mají větší váhu při výpočtu průměru (nejhorší jedinci se dokonce mohou úplně ignorovat). Kromě těchto dvou nejčastěji používaných rekombinací se dají používat i křížení známá z genetických algoritmů, není to ale moc obvyklé. Existuje i uniformní rekombinace, která každou složku vektoru jedince vybírá z náhodného jedince v populace. 

Použitá rekombinace se občas objevuje i v notaci evolučních strategií, v takovém případě se píše jako $(\lambda/\rho + \mu)$, kde právě $\rho$ označuje použitou rekombinaci.

Základním operátorem v evolučních strategiích ale je mutace. Typicky jde o gaussovskou mutaci s určitým rozptylem. Zde se objevuje několik možností, kde nejjednodušší je sférická mutace, která přičítá k jedinci vektor z normálního rozdělení $\sigma\normal{0}{I}$, kde $I$ je jednotková matice. O něco složitější varianta potom používá jiný rozptyl pro každou souřadnici vektoru, tj. k jedinci se přičítá hodnota z normálního rozdělení $\normal{0}{\mathrm{diag}({\vec{\sigma}})}$, kde $\mathrm{diag}(\sigma)$ značí diagonální matici s vektorem $\vec{\sigma}$ na hlavní diagonále. Konečně v nejkomplikovanějším případě se jedinci generují s normálního rozdělení s plnou kovarianční matici $\normal{0}{\Sigma}$. Ačkoliv první dva způsoby vyžadují mnohem nižší množství endogenních parametrů (1 respektive $d$), jejich nevýhoda spočívá v tom, že nejsou schopny zachytit závislosti mezi parametry a hodí se tak především pro separabilní problémy. Na druhou stranu způsob s plnou kovarianční maticí je invariantní vůči rotacím a škálovaní prohledávaného prostoru (a díky dalším vlastnostem evolučních strategií i k monotónnímu škálování fitness funkce).

Vzhledem k relativně velkému množství endogenních parametrů v evolučních strategiích a k tomu, že vhodné nastavení parametrů je různé pro různé optimalizační problémy a dokonce i v různých fázích evoluce, vznikla potřeba parametry nastavovat adaptivně. Při pevném nastavení velikosti mutace typicky pozorujeme tři fáze evoluce. V první fázi evoluce je konvergence pomalá, protože změny dělané mutací jsou příliš malé. Následuje fáze rychlé konvergence, kde jsou velikosti změn optimální pro danou fázi výpočtu, a v poslední fázi se konvergence zase zpomalí, protože jsou změny moc velké (algoritmus ``skáče'' kolem optima).

\newcommand{\fifth}{\sfrac{1}{5}\xspace}

\section{Pravidlo jedné pětiny}

První metoda adaptivního nastavování vzešla z Rechenbergových experimentů,\cite{rechenberg1973} které zkoumaly vliv rozptylu Gaussovské mutace v $(1+1)$-ES při optimalizaci dvou funkcí. Ukázalo se, že pro obě funkce algoritmus nejrychleji konverguje, pokud se velikost mutace zmenší, když je pravděpodobnost, že je potomek lepší než rodič menší než cca \fifth, a zvětší, když je tato pravděpodobnost větší než cca \fifth. Z tohoto pozorování vzniklo pravidlo \fifth.\sidenote{V angličtině ``one fifth rule''}

Proč takové pravidlo funguje? Představme si optimalizaci lineární funkce, v takovém případě je pravděpodobnost, že potomek je lepší než rodič, přesně 50\%. 
Obecnou funkci můžeme v každém bodě podle Taylorova pravidla aproximovat pomocí lineární funkce, tato aproximace je tím přesnější, čím blíže jsme bodu, ve kterém jsme funkci aproximovali, tedy, při malé velikosti mutace bude většina potomků blízko a pravděpodobnost, že jsou lepší než rodič, je kolem 50\%. Naopak, při nekonečném rozptylu mutace pravděpodobnost zlepšení odpovídá části prostoru, kde má funkce lepší hodnotu, než v daném bodě. Ve chvíli, kdy se algoritmu přiblíží optimu je tato pravděpodobnost většinou blízko 0. Ve skutečnosti se dokonce ukazuje, že pro většinu funkcí pravděpodobnost zlepšení monotónně roste s klesajícím rozptylem mutace. Přesná hodnota pro optimální pravděpodobnost zlepšení závisí na optimalizované funkci, nicméně právě \fifth je často doporučovaná.

Implementace pravidla \fifth je velmi jednoduchá. Může vypadat například tak, že se rozptyl upravuje podle vztahu 
$$\sigma = \sigma\exp^{1/\sqrt{d+1}}(\mathbb{1}_{f(\vec{x_1})<f(\vec{x})}-\fifth)\,,$$ kde $\mathbb{1}$ je charakteristická funkce (tj. $\mathbb{1}(\varphi) = 1$, pokud $\varphi$ je pravdivý výraz a $0$ jinak), $\vec{x_1}$ je potomek rodiče $\vec{x}$ a $d$ je počet proměnných daného optimalizačního problému.

\section{Sebe-adaptivní evoluční strategie}

Jiný přístup k sebe-adaptaci endogenních parametrů zvolil Schweffel\cite{schwefel1977numerische}, ten pro jejich ladění použil podobné genetické operátory, jako se používají pro samotné zakódované řešení. Základní myšlenka je, že se každý endogenní parametr vynásobí číslem $\exp(\normal{0}{I})$. Hlavním důvodem pro použití takové ``multiplikativní'' mutace je to, že relativní velikost změn oběma směry je stejná a navíc se vyvíjí vyvíjí rozptyly pro mutaci, které musí být vždy kladné. Aditivní mutace se v takovém případě moc nehodí.

Celkově se dá tato evoluční strategie (nazývaná $(\mu/\mu, \lambda)-\sigma\text{SA-ES}$ zapsat jako v algoritmu \ref{alg:sigmaSAES} níže. Můžeme si všimnout hned několika věcí -- mutace pro jedince i pro parametry je podobná, až na to, že mutace parametrů je multiplikativní a mutace jedince aditivní. Rekombinace se chová opět stejně pro jedince i pro jim příslušné parametry mutace -- počítá se průměr přes všechny jedince v populaci. Díky tomu, že je rekombinace deterministická, stačí ji dělat jen jednou za iteraci, proto se dělá mimo \code{for} cyklus.

\begin{algorithm}
\caption{Evoluční strategie s adaptací rozptylů mutace, $d$ značí počet proměnných problému, $\circ$ je operace násobení vektoru po složkách}
\label{alg:sigmaSAES}
\begin{algorithmic}[1]
\Require $d \in \Nat_+, \lambda \geq 5d, \mu \approx \lambda/4, \tau \approx 1/\sqrt{d}, \tau_i \approx 1/d^{1/4}$
\Procedure{$(\mu/\mu, \lambda)$-$\sigma\text{SA-ES}$}{} 
\State inicializuj $\vec{x} \in \Real^n, \vec{\sigma} \in \Real^n_+$
\While {není konec}
	\For {$k \in {1, \dots, \lambda}$}
		\State $\xi_k = \tau\normal{0}{1}$ \Comment{globální rozptyl}
		\State $\vec{\xi_k} = \tau_i\normal{0}{\identity}$ \Comment{rozptyl pro souřadnice}
		\State $\vec{z_k} = \normal{0}{\identity}$ \Comment{změna řešení $\vec{x}$}
		\State $\vec{\sigma_k} = \sigma \circ \exp(\vec{\xi_k})\exp(\xi_k)$
		\State $\vec{x_k} = \vec{x} + \vec{\sigma_k}\circ\vec{z_k}$
	\EndFor
	\State $\mathcal{P} = \text{vyber } \mu \text{ nejlepších z } \{(\vec{x_i}, \vec{\sigma_i})\,|\,i \in \{1, \dots, k\}\}$
	\State $\vec{\sigma} = \frac{1}{\mu}\sum_{\vec{\sigma_k} \in \mathcal{P}}\vec{\sigma_k}$
	\State $\vec{x} = \frac{1}{\mu}\sum_{\vec{x_k} \in \mathcal{P}}\vec{x_k}$
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

Mezi Rechenbergovým a Schwefelovým přístupem je rozdíl i v tom, že ten druhý nastavuje různé rozptyly mutace pro různé souřadnice, původní Rechenbergův přístup pracuje jen s jedním rozptylem a tedy se sférickou mutací.

Přestože jsou relativní změny rozptylů nestranné, ukazuje se, že algoritmus má v případě neutrální selekce\sidenote{Neutrální selekce je nezávislá na fitness jedince, dá se implementovat např. tak, že je fitness konstantní a nejlepší jedinci se vybírají náhodně. Občas se používá při analýze chování algoritmů.} tendenci velikost rozptylu zvyšovat. Tomu se dá předejít použití větší velikosti populace. Nicméně moderní evoluční strategie z tohoto důvodu přistupují k deterministickým (někdy se používá termín ``derandomizovaným'') metodám nastavení endogenních parametrů.

\section{Kumulativní adaptace velikosti kroku}

Jedním ze způsobů odstranění náhody z adaptace evolučních strategií je použití tzv. \emph{evoluční cesty}, je to vlastně vektor, ve kterém se ukládají průměrné změny v každém směru u jedinců, kteří projdou selekcí. Z velikosti těchto změn se potom spočítá nový vektor rozptylů. Právě takovou techniku používá algoritmus založený na kumulativní změně velikosti kroku (Cumulative Step-Size Adaptation -- CSA)\sidenote{Rozptyl gaussovské mutace se v evolučních strategiích také označuje jako velikost kroku -- anglicky ``step-size''} vytvořený Ostermeierm \emph{a spol.}\cite{Ostermeier1994} Přesný popis CSA je uveden jako Algoritmus \ref{alg:CSA}. 

Základ algoritmu je podobný výše uvedenému algoritmu z adaptací rozptylů, ale vidíme, že adaptace nyní není založena na náhodně, ale počítá se právě z evoluční cesty $\vec{s_\sigma}$. Aby se zabránilo přílišným oscilacím evoluční cesty způsobeným náhodným samplováním, vektor se průměruje s vektorem z předcházejícího kroku. Relativně složité koeficienty, které se při výpočtu průměru používají, jsou zvoleny tak, aby se očekávaná velikost kroku neměnila při neutrální selekci.

\begin{algorithm}
\caption{Evoluční strategie s koordinovanou adaptací velikosti kroku, $d$ značí počet proměnných problému, $\circ$ je operace násobení vektoru po složkách}
\label{alg:CSA}
\begin{algorithmic}[1]
\Require{$d \in \Nat_+, \lambda \in \Nat, \mu \approx \lambda/4, c_\sigma \approx \sqrt{\mu/(d+\mu)}, f \approx 1 + \sqrt{\mu/d}, f_i \approx 3d$}
\Procedure{$(\mu/\mu,\lambda)$-ES s evoluční cestou}{}
\State Inicializuj $\vec{x} \in \Real^d, \vec{\sigma} \in \Real^n_+$
\While{není konec}
	\For{$k \in \{1, \dots, \lambda\}$}
	  \State $\vec{z_k} = \normal{0}{\identity}$
	  \State $\vec{x_k} = \vec{x} + \vec{\sigma} \circ \vec{z_k}$ \Comment{mutace}
	\EndFor
	\State $\mathcal{P} = \text{vyber } \mu \text{ nejlepších jedinců z } \{(\vec{x_k}, \vec{z_k}) | 1 \leq k \leq \lambda\}$
	\State $\vec{s_\sigma} = (1 - c_\sigma)\vec{s_\sigma} + \sqrt{c_\sigma(2-c_\sigma)}\frac{\sqrt{\mu}}{\mu}\sum_{z_k \in \mathcal{P}}\vec{z_k} $ \Comment{evoluční cesta}
	\State $\vec{\sigma} = \vec{\sigma} \circ \exp^{1/f_i}\big(\frac{|\vec{s_\sigma}|}{\mathbb{E}|\normal{0}{1}|}\big)\exp^{c_\sigma/f}\big(\frac{||\vec{s_\sigma}||}{\mathbb{E}||\normal{0}{\identity}||} \big)$
	\State $\vec{x} = \frac{1}{\mu} \sum_{\vec{x_k}\in\mathcal{P}}\vec{x_k}$ \Comment{rekombinace}
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

